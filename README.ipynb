{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [1 Contact](#1-Contact)\n",
    "* [2 Install](#2-Install)\n",
    "  * [2.1 Dependencies](#2.1-Dependencies)\n",
    "  * [2.2 Quick install](#2.2-Quick-install)\n",
    "  * [2.3 Detailed Package Install Instructions](#2.3-Detailed-Package-Install-Instructions)\n",
    "* [3 REMMAX function](#3-REMMAX-function)\n",
    "  * [3.1 Format of the input file](#3.1-Format-of-the-input-file)\n",
    "  * [3.2 Exhaustive additive by addtive epistatis](#3.2-Exhaustive-additive-by-addtive-epistatis)\n",
    "    * [3.2.1 Include additive and additive by additive genomic relationship matrix](#3.2.1-Include-additive-and-additive-by-additive-genomic-relationship-matrix)\n",
    "    * [3.2.2 Include additive, dominance and additive by additive genomic relationship matrix](#3.2.2-Include-additive,-dominance-and-additive-by-additive-genomic-relationship-matrix)\n",
    "    * [3.2.3 Include additive, dominance and three kinds of epistatic genomic relationship matrix](#3.2.3-Include-additive,-dominance-and-three-kinds-of-epistatic-genomic-relationship-matrix)\n",
    "  * [3.3 Exhaustive additive by dominance epistatis](#3.3-Exhaustive-additive-by-dominance-epistatis)\n",
    "  * [3.4 Exhaustive dominance by dominance epistatis](#3.4-Exhaustive-dominance-by-dominance-epistatis)\n",
    "\n",
    "# 1 Contact\n",
    "Chao Ning  \n",
    "ningchao(at)sdau(dot)edu(dot)cn  \n",
    "ningchao91(at)gmail(dot)com  \n",
    "\n",
    "# 2 Install\n",
    "We will keep GMAT updated. Please uninstall older version to obtain the latest functions. The easiest uninstall way:  \n",
    "\\> pip uninstall gmat\n",
    "\n",
    "## 2.1 Dependencies\n",
    "* numpy>=1.16.0  \n",
    "* pandas>=0.19.0  \n",
    "* scipy>=1.1.1  \n",
    "* cffi>=1.12.0  \n",
    "* pandas_plink>=2.0.0  \n",
    "* tqdm>=4.43.0  \n",
    "\n",
    "We recommend using a Python distribution such as [Anaconda](https://www.anaconda.com/distribution/) (Python 3.7 version). This distribution can be used on Linux and Windows. It is the easiest way to get all the required package dependencies. \n",
    "\n",
    "## 2.2 Quick install\n",
    "\\> pip install gmat  \n",
    "\n",
    "## 2.3 Detailed Package Install Instructions\n",
    "(1) Install the dependent packages  \n",
    "(2) Go to the directory of GMAT and type  \n",
    "\\> python setup.py install  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 REMMAX function  \n",
    "Rapid Epistatic Mixed Model Association Studies\n",
    "\n",
    "***Cite***:  \n",
    "* Dan Wang, Hui Tang, Jian-Feng Liu, Shizhong Xu, Qin Zhang and Chao Ning. Rapid Epistatic Mixed Model Association Studies by Controlling Multiple Polygenic Effects. *BioRxiv*, 2020. doi: https://doi.org/10.1101/2020.03.05.976498  \n",
    "* Chao Ning, Dan Wang, Huimin Kang, Raphael Mrode, Lei Zhou, Shizhong Xu, Jian-Feng Liu. A rapid epistatic mixed-model association analysis by linear retransformations of genomic estimated values. *Bioinformatics*, 2018, 34(11): 1817-1825.  \n",
    "\n",
    "## 3.1 Format of the input file\n",
    "* Plink binary file including \\*.bed, \\*.bim and \\*.fam.  \n",
    "Missing genotypes are recommended to impute with Beagle or other softwares, although they will be imputed according the frequency of occurrence.   \n",
    "\n",
    "* phenotypic file:  \n",
    "(1) Delimited by blanks or tabs;  \n",
    "(2) All individuals in the plink file must have phenotypic values. If no, please remove these individuals from the plink binary file;  \n",
    "(3) The fisrt column is the family id and the second column is the individual id. The first two columns are the same to plink fam file, but order can be different;  \n",
    "(4) The last column is the phenotypic values. **Miss values are not allowed**;  \n",
    "(5) The covariates (including population means) are put before the phenotypic column. A column of 1’s must be contained.  \n",
    "(6) Repeated mesures are allowed for individuals.\n",
    "An example phenotypic file with four covariates (population mean, sex, age, treatmeant or untreatmeant) is as follows:  \n",
    "12659\t14462\t1\t0\t126\t0\t0.58  \n",
    "12659\t14463\t1\t0\t91\t1\t0.39  \n",
    "12659\t14464\t1\t1\t126\t0\t0.37  \n",
    "12659\t14465\t1\t0\t91\t1\t0.9  \n",
    "12659\t14466\t1\t0\t91\t1\t0.84  \n",
    "12659\t14467\t1\t0\t91\t1\t0.61  \n",
    "12659\t14468\t1\t1\t91\t1\t0.84  \n",
    "An example phenotypic file with repeated mesures is as follows:  \n",
    "0 01_01 1 -2.25383070574996  \n",
    "0 01_02 1 -1.88774565927855  \n",
    "0 01_03 1 2.4150679267528  \n",
    "0 01_03 1 -0.320697695608065  \n",
    "0 01_04 1 2.41743663901475  \n",
    "0 01_06 1 -0.634513668596019  \n",
    "0 01_06 1 -1.4489729404784  \n",
    "0 01_07 1 1.92328500921367  \n",
    "0 01_07 1 1.54547583777757  \n",
    "  \n",
    "## 3.2 Exhaustive additive by addtive epistatis  \n",
    "Data: Mouse data in directory of GMAT/examples/data/mouse    \n",
    "\n",
    "### 3.2.1 Include additive and additive by additive genomic relationship matrix\n",
    "#### (1)  Exact test (for small data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gmat.gmatrix import agmat\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma.remma_epiAA import remma_epiAA\n",
    "from gmat.remma import annotation_snp_pos\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "pheno_file = 'pheno'  # phenotypic file\n",
    "bed_file = 'plink'  # the prefix for the plink binary file\n",
    "\n",
    "# Step 1: Calculate the genomic relationship matrix\n",
    "agmat(bed_file) \n",
    "ag = np.loadtxt(bed_file + '.agrm0')  # load the additive genomic relationship matrix\n",
    "\n",
    "# Step 2: Prepare the phenotypic vector (y), designed matrix for fixed effects (xmat) and designed matrix for random effects (zmat)\n",
    "y, xmat, zmat = design_matrix_wemai_multi_gmat(pheno_file, bed_file)\n",
    "\n",
    "# Step 3: Estimate the variances\n",
    "gmat_lst = [ag, ag*ag]  # ag*ag is the additive by additive genomic relationship matrix\n",
    "var_a_axa = wemai_multi_gmat(y, xmat, zmat, gmat_lst)\n",
    "print(var_a_axa)  # a list： [0] addtive variance; [1] additive by additive variance; [2] residual variance\n",
    "\n",
    "# Step 4: Test\n",
    "remma_epiAA(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, p_cut=0.0001, out_file='epiAA_a_axa')\n",
    "\n",
    "# Step 5: Select top SNPs and add the SNP position\n",
    "res_file = 'epiAA_a_axa'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5, dis=0)  # p values < 1.0e-5 and the distance between SNP pairs > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Parallel exact test  (for small data)\n",
    "Analysis can be subdivided with remma_epiAA_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gmat.gmatrix import agmat\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "pheno_file = 'pheno'  # phenotypic file\n",
    "bed_file = 'plink'  # the prefix for the plink binary file\n",
    "\n",
    "# Write codes of step 1-4 in separate scripts and run separately\n",
    "# Step 1-3 is same to the above\n",
    "\n",
    "# Step 4: parallel test.\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, parallel=[3,1], \n",
    "                         p_cut=0.0001, out_file='epiAA_parallel_a_axa')\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, parallel=[3,2], \n",
    "                         p_cut=0.0001, out_file='epiAA_parallel_a_axa')\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, parallel=[3,3], \n",
    "                         p_cut=0.0001, out_file='epiAA_parallel_a_axa')\n",
    "\n",
    "# Step 5: Merge files 'epiAA_parallel_a_axa.1', 'epiAA_parallel_a_axa.2' and 'epiAA_parallel_a_axa.3' with the following codes.\n",
    "prefix = 'epiAA_parallel_a_axa'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1):\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 6: Select top SNPs and add the SNP position\n",
    "res_file = 'epiAA_parallel_a_axa.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5, dis=0)  # p values < 1.0e-5 and the distance between SNP pairs > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) approximate test (recommended for big data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gmat.gmatrix import agmat\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma import random_pair\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_pair, remma_epiAA_eff\n",
    "from gmat.remma import annotation_snp_pos\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "pheno_file = 'pheno'  # phenotypic file\n",
    "bed_file = 'plink'  # the prefix for the plink binary file\n",
    "\n",
    "# Step 1-3 is same to exact test\n",
    "\n",
    "# Step 4: Randomly select 100,000 SNP pairs\n",
    "snp_df = pd.read_csv(bed_file + '.bim', header=None, sep='\\s+')\n",
    "num_snp = snp_df.shape[0]  # the number of snp\n",
    "random_pair(num_snp, out_file='random_pair', num_pair=100000, num_each_pair=5000)\n",
    "\n",
    "# step 5: Test these 100,000 SNP pairs\n",
    "# note: set p_cut=1 to save all the results\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, snp_pair_file=\"random_pair\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAA_pair_random_a_axa')\n",
    "\n",
    "# step 6: Calculate the median of variances for estimated epistatic SNP effects\n",
    "res_df = pd.read_csv('epiAA_pair_random_a_axa', header=0, sep='\\s+')\n",
    "print(np.median(res_df['p']))  # P value close to 0.5. It means type I error controlled well\n",
    "var_median = np.median(res_df['var'])  # median of variances for estimated epistatic SNP effects\n",
    "\n",
    "# step 7: Screen the effects and select top SNP pairs based on approximate test. \n",
    "# Use the above median of variances as the approximate values (var_app = var_median)\n",
    "remma_epiAA_eff(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, var_app=var_median, \n",
    "                      p_cut=1e-05, out_file='epiAA_eff_a_axa')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, snp_pair_file=\"epiAA_eff_a_axa\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAA_pair_res_a_axa')\n",
    "\n",
    "# Step 9: Select top SNPs and add the SNP position\n",
    "res_file = 'epiAA_pair_res_a_axa'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5, dis=0)  # p values < 1.0e-5 and the distance between SNP pairs > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Parallel approximate test (recommended for big data)\n",
    "Analysis can be subdivided with remma_epiAA_eff_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gmat.gmatrix import agmat\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma import random_pair\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_pair, remma_epiAA_eff\n",
    "from gmat.remma import annotation_snp_pos\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "pheno_file = 'pheno'  # phenotypic file\n",
    "bed_file = 'plink'  # the prefix for the plink binary file\n",
    "\n",
    "# Step 1-3 is same to exact test\n",
    "\n",
    "# Step 4: Randomly select 100,000 SNP pairs\n",
    "snp_df = pd.read_csv(bed_file + '.bim', header=None, sep='\\s+')\n",
    "num_snp = snp_df.shape[0]  # the number of snp\n",
    "random_pair(num_snp, out_file='random_pair', num_pair=100000, num_each_pair=5000)\n",
    "\n",
    "# step 5: Test these 100,000 SNP pairs\n",
    "# note: set p_cut=1 to save all the results\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, snp_pair_file=\"random_pair\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAA_pair_random_a_axa')\n",
    "\n",
    "# step 6: Calculate the median of variances for estimated epistatic SNP effects\n",
    "res_df = pd.read_csv('epiAA_pair_random_a_axa', header=0, sep='\\s+')\n",
    "print(np.median(res_df['p']))  # P value close to 0.5. It means type I error controlled well\n",
    "var_median = np.median(res_df['var'])  # median of variances for estimated epistatic SNP effects\n",
    "\n",
    "# step 7: Screen the effects and select top SNP pairs based on approximate test. \n",
    "# Use the above median of variances as the approximate values (var_app = var_median)\n",
    "remma_epiAA_eff(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, var_app=var_median, \n",
    "                      p_cut=1e-05, out_file='epiAA_eff_a_axa')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_a_axa, bed_file=bed_file, snp_pair_file=\"epiAA_eff_a_axa\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAA_pair_res_a_axa')\n",
    "\n",
    "# Step 9: Select top SNPs and add the SNP position\n",
    "res_file = 'epiAA_pair_res_a_axa'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5, dis=0)  # p values < 1.0e-5 and the distance between SNP pairs > 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Include additive, dominance and additive by additive genomic relationship matrix\n",
    "#### (1) Exact test (for small data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gmat.gmatrix import agmat, dgmat_as\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma.remma_epiAA import remma_epiAA, remma_epiAA_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pheno_file = 'pheno'\n",
    "bed_file = 'plink'\n",
    "\n",
    "# Step 1: Calculate the genomic relationship matrix\n",
    "agmat_lst = agmat(bed_file, inv=False) # additive genomic relationship matrix\n",
    "dgmat_lst = dgmat_as(bed_file, inv=False) # dominace genomic relationship matrix\n",
    "\n",
    "# Step 2: Prepare the phenotypic vector (y), designed matrix for fixed effects (xmat) and designed matrix for random effects (zmat)\n",
    "y, xmat, zmat = design_matrix_wemai_multi_gmat(pheno_file, bed_file)\n",
    "\n",
    "# Step 3: Estimate the variances\n",
    "gmat_lst = [agmat_lst[0], dgmat_lst[0], agmat_lst[0]*agmat_lst[0]]  # agmat_lst[0]*agmat_lst[0] is the additive by additive genomic relationship matrix\n",
    "var_com_a_d_axa = wemai_multi_gmat(y, xmat, zmat, gmat_lst)\n",
    "print(var_com_a_d_axa)  # a list： [0] addtive variance; [1] dominace variance [2] additive by additive variance; [3] residual variance\n",
    "\n",
    "# Step 4: Test\n",
    "remma_epiAA(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, p_cut=0.0001, out_file='remma_epiAA_a_d_axa')\n",
    "\n",
    "# Step 5: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAA_a_d_axa'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5, dis=0)  # p values < 1.0e-5 and the distance between SNP pairs > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Parallel exact test (for small data)\n",
    "Analysis can be subdivided with remma_epiAA_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write codes of step 1-4 in separate scripts and run separately\n",
    "# Step 1-3 is same to the above\n",
    "\n",
    "# Step 4: parallel test. Write the codes in separate scripts and run separately.\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_parallel\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, parallel=[3,1], \n",
    "                         p_cut=0.0001, out_file='remma_epiAA_parallel_a_d_axa')\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, parallel=[3,2], \n",
    "                         p_cut=0.0001, out_file='remma_epiAA_parallel_a_d_axa')\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, parallel=[3,3], \n",
    "                         p_cut=0.0001, out_file='remma_epiAA_parallel_a_d_axa')\n",
    "\n",
    "# Step 5: Merge files 'remma_epiAA_parallel_a_d_axa.1', 'remma_epiAA_parallel_a_d_axa.2' and 'remma_epiAA_parallel_a_d_axa.3' with the following codes.\n",
    "prefix = 'remma_epiAA_parallel_a_d_axa'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1):\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 6: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAA_parallel_a_d_axa.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5, dis=0)  # p values < 1.0e-5 and the distance between SNP pairs > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) approximate test (recommended for big data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "from gmat.gmatrix import agmat, dgmat_as\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma import random_pair\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_pair, remma_epiAA_eff, remma_epiAA_eff_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pheno_file = 'pheno'  # phenotypic file\n",
    "bed_file = 'plink'  # the prefix for the plink binary file\n",
    "\n",
    "# Step 1-3 is same to exact test\n",
    "\n",
    "# Step 4: Randomly select 100,000 SNP pairs\n",
    "snp_df = pd.read_csv(bed_file + '.bim', header=None, sep='\\s+')\n",
    "num_snp = snp_df.shape[0]  # the number of snp\n",
    "random_pair(num_snp, out_file='random_pair', num_pair=100000, num_each_pair=5000)\n",
    "\n",
    "# step 5: Test these 100,000 SNP pairs\n",
    "# note: set p_cut=1 to save all the results\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, snp_pair_file=\"random_pair\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_random_a_d_axa')\n",
    "\n",
    "# step 6: Calculate the median of variances for estimated epistatic SNP effects\n",
    "res_df = pd.read_csv('remma_epiAA_pair_random_a_d_axa', header=0, sep='\\s+')\n",
    "print(np.median(res_df['p']))  # P value close to 0.5. It means type I error controlled well\n",
    "var_median = np.median(res_df['var'])  # median of variances for estimated epistatic SNP effects\n",
    "\n",
    "# step 7: Screen the effects and select top SNP pairs based on approximate test. \n",
    "# Use the above median of variances as the approximate values (var_app = var_median)\n",
    "remma_epiAA_eff(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, var_app=var_median, \n",
    "                      p_cut=1e-05, out_file='remma_epiAA_eff_a_d_axa')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, snp_pair_file=\"remma_epiAA_eff_a_d_axa\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_res_a_d_axa')\n",
    "\n",
    "# Step 9: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAA_pair_res_a_d_axa'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5, dis=0)  # p values < 1.0e-5 and the distance between SNP pairs > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Parallel approximate test (recommended for big data)\n",
    "Analysis can be subdivided with remma_epiAA_eff_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write codes of step 1-8 in separate scripts and run separately\n",
    "# Step 1-6 is same to the above\n",
    "\n",
    "# Step 7: parallel test. Write the codes in separate scripts and run separately.\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_eff_parallel\n",
    "remma_epiAA_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, parallel=[3,1], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='remma_epiAA_eff_parallel_a_d_axa')\n",
    "remma_epiAA_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, parallel=[3,2], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='remma_epiAA_eff_parallel_a_d_axa')\n",
    "remma_epiAA_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, parallel=[3,3], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='remma_epiAA_eff_parallel_a_d_axa')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, snp_pair_file=\"remma_epiAA_eff_parallel_a_d_axa.1\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_parallel_a_d_axa.1')\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, snp_pair_file=\"remma_epiAA_eff_parallel_a_d_axa.2\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_parallel_a_d_axa.2')\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_a_d_axa, bed_file=bed_file, snp_pair_file=\"remma_epiAA_eff_parallel_a_d_axa.3\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_parallel_a_d_axa.3')\n",
    "\n",
    "# Step 9: Merge files 'epiAA_pair_res_a_d_axa.1', 'epiAA_pair_res_a_d_axa.2' and 'epiAA_pair_res_a_d_axa.3' \n",
    "# with the following codes.\n",
    "prefix = 'remma_epiAA_pair_parallel_a_d_axa'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1:\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 10: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAA_pair_parallel_a_d_axa.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5, dis=0)  # p values < 1.0e-5 and the distance between SNP pairs > 0\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Include additive, dominance and three kinds of epistatic genomic relationship matrix\n",
    "additive, dominance, additive by additive, additive by dominance and dominance by dominance genomic relationship matrix   \n",
    "#### (1) Exact test (for small data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gmat.gmatrix import agmat, dgmat_as\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma.remma_epiAA import remma_epiAA, remma_epiAA_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pheno_file = 'pheno'\n",
    "bed_file = 'plink'\n",
    "\n",
    "# Step 1: Calculate the genomic relationship matrix\n",
    "agmat_lst = agmat(bed_file, inv=False) # additive genomic relationship matrix\n",
    "dgmat_lst = dgmat_as(bed_file, inv=False) # dominace genomic relationship matrix\n",
    "\n",
    "# Step 2: Prepare the phenotypic vector (y), designed matrix for fixed effects (xmat) and designed matrix for random effects (zmat)\n",
    "y, xmat, zmat = design_matrix_wemai_multi_gmat(pheno_file, bed_file)\n",
    "\n",
    "# Step 3: Estimate the variances\n",
    "# agmat_lst[0]*agmat_lst[0] is the additive by additive genomic relationship matrix\n",
    "# agmat_lst[0]*dgmat_lst[0] is the additive by dominance genomic relationship matrix\n",
    "# dgmat_lst[0]*dgmat_lst[0] is the dominance by dominance genomic relationship matrix\n",
    "gmat_lst = [agmat_lst[0], dgmat_lst[0], agmat_lst[0]*agmat_lst[0], agmat_lst[0]*dgmat_lst[0], dgmat_lst[0]*dgmat_lst[0]]  \n",
    "\n",
    "var_com_all = wemai_multi_gmat(y, xmat, zmat, gmat_lst)\n",
    "print(var_com_all)  # a list： [0] addtive variance; [1] dominace variance [2] additive by additive variance; [3] residual variance\n",
    "\n",
    "# Step 4: Test\n",
    "remma_epiAA(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, p_cut=0.0001, out_file='remma_epiAA')\n",
    "\n",
    "# Step 5: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAA'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Parallel exact test (for small data)\n",
    "Analysis can be subdivided with remma_epiAA_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1-3 is same to the above\n",
    "\n",
    "# Step 4: parallel test. Write the codes in separate scripts and run separately.\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_parallel\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,1], \n",
    "                         p_cut=0.0001, out_file='remma_epiAA_parallel')\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,2], \n",
    "                         p_cut=0.0001, out_file='remma_epiAA_parallel')\n",
    "remma_epiAA_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,3], \n",
    "                         p_cut=0.0001, out_file='remma_epiAA_parallel')\n",
    "\n",
    "# Step 5: Merge files 'remma_epiAA_parallel.1', 'remma_epiAA_parallel.2' and 'remma_epiAA_parallel.3' with the following codes.\n",
    "prefix = 'remma_epiAA_parallel'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1):\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 6: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAA_parallel.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) approximate test (recommended for big data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "from gmat.gmatrix import agmat, dgmat_as\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma import random_pair\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_pair, remma_epiAA_eff, remma_epiAA_eff_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pheno_file = 'pheno'  # phenotypic file\n",
    "bed_file = 'plink'  # the prefix for the plink binary file\n",
    "\n",
    "# Step 1-3 is same to exact test\n",
    "\n",
    "# Step 4: Randomly select 100,000 SNP pairs\n",
    "snp_df = pd.read_csv(bed_file + '.bim', header=None, sep='\\s+')\n",
    "num_snp = snp_df.shape[0]  # the number of snp\n",
    "random_pair(num_snp, out_file='random_pair', num_pair=100000, num_each_pair=5000)\n",
    "\n",
    "# step 5: Test these 100,000 SNP pairs\n",
    "# note: set p_cut=1 to save all the results\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"random_pair\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_random')\n",
    "\n",
    "# step 6: Calculate the median of variances for estimated epistatic SNP effects\n",
    "res_df = pd.read_csv('remma_epiAA_pair_random', header=0, sep='\\s+')\n",
    "print(np.median(res_df['p']))  # P value close to 0.5. It means type I error controlled well\n",
    "var_median = np.median(res_df['var'])  # median of variances for estimated epistatic SNP effects\n",
    "\n",
    "# step 7: Screen the effects and select top SNP pairs based on approximate test. \n",
    "# Use the above median of variances as the approximate values (var_app = var_median)\n",
    "remma_epiAA_eff(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, var_app=var_median, \n",
    "                      p_cut=1e-05, out_file='remma_epiAA_eff')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"remma_epiAA_eff\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_res')\n",
    "\n",
    "# Step 9: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAA_pair_res'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Parallel approximate test (recommended for big data)\n",
    "Analysis can be subdivided with remma_epiAA_eff_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1-6 is same to the above\n",
    "\n",
    "# Step 7: parallel test. Write the codes in separate scripts and run separately.\n",
    "from gmat.remma.remma_epiAA import remma_epiAA_eff_parallel\n",
    "remma_epiAA_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,1], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='remma_epiAA_eff_parallel')\n",
    "remma_epiAA_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,2], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='remma_epiAA_eff_parallel')\n",
    "remma_epiAA_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,3], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='remma_epiAA_eff_parallel')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"remma_epiAA_eff_parallel.1\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_res.1')\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"remma_epiAA_eff_parallel.2\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_res.2')\n",
    "remma_epiAA_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"remma_epiAA_eff_parallel.3\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='remma_epiAA_pair_res.3')\n",
    "\n",
    "# Step 9: Merge files 'remma_epiAA_pair_res.1', 'remma_epiAA_pair_res.2' and 'remma_epiAA_pair_res.3' \n",
    "# with the following codes.\n",
    "prefix = 'remma_epiAA_pair_res'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1):\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 10: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAA_pair_res.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Exhaustive additive by dominance epistatis  \n",
    "Include additive, dominance, additive by additive, additive by dominance and dominance by dominance genomic relationship matrix  \n",
    "#### (1) Exact test (for small data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gmat.gmatrix import agmat, dgmat_as\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma.remma_epiAD import remma_epiAD, remma_epiAD_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pheno_file = 'pheno'\n",
    "bed_file = 'plink'\n",
    "\n",
    "# Step 1: Calculate the genomic relationship matrix\n",
    "agmat_lst = agmat(bed_file, inv=False) # additive genomic relationship matrix\n",
    "dgmat_lst = dgmat_as(bed_file, inv=False) # dominace genomic relationship matrix\n",
    "\n",
    "# Step 2: Prepare the phenotypic vector (y), designed matrix for fixed effects (xmat) and designed matrix for random effects (zmat)\n",
    "y, xmat, zmat = design_matrix_wemai_multi_gmat(pheno_file, bed_file)\n",
    "\n",
    "# Step 3: Estimate the variances\n",
    "# agmat_lst[0]*agmat_lst[0] is the additive by additive genomic relationship matrix\n",
    "# agmat_lst[0]*dgmat_lst[0] is the additive by dominance genomic relationship matrix\n",
    "# dgmat_lst[0]*dgmat_lst[0] is the dominance by dominance genomic relationship matrix\n",
    "gmat_lst = [agmat_lst[0], dgmat_lst[0], agmat_lst[0]*agmat_lst[0], agmat_lst[0]*dgmat_lst[0], dgmat_lst[0]*dgmat_lst[0]]  \n",
    "\n",
    "var_com_all = wemai_multi_gmat(y, xmat, zmat, gmat_lst)\n",
    "print(var_com_all)  \n",
    "\"\"\"\n",
    "a list： [0] addtive variance; [1] dominace variance [2] additive by additive variance; [3] additive by dominance variance; \n",
    "[4] dominance by dominance variance; [5] residual variance\n",
    "\"\"\"\n",
    "\n",
    "# Step 4: Test\n",
    "remma_epiAD(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, p_cut=0.0001, out_file='epiAD')\n",
    "\n",
    "# Step 5: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiAD'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Parallel exact test (for small data)\n",
    "Analysis can be subdivided with remma_epiAD_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1-3 is same to the above\n",
    "\n",
    "# Step 4: parallel test. Write the codes in separate scripts and run separately.\n",
    "from gmat.remma.remma_epiAD import remma_epiAD_parallel\n",
    "remma_epiAD_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,1], \n",
    "                         p_cut=0.0001, out_file='epiAD_parallel')\n",
    "remma_epiAD_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,2], \n",
    "                         p_cut=0.0001, out_file='epiAD_parallel')\n",
    "remma_epiAD_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,3], \n",
    "                         p_cut=0.0001, out_file='epiAD_parallel')\n",
    "\n",
    "# Step 5: Merge files 'epiAD_parallel.1', 'epiAD_parallel.2' and 'epiAD_parallel.3' with the following codes.\n",
    "prefix = 'epiAD_parallel'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1):\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 6: Select top SNPs and add the SNP position\n",
    "res_file = 'epiAD_parallel.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) approximate test (recommended for big data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "from gmat.gmatrix import agmat, dgmat_as\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma import random_pairAD\n",
    "from gmat.remma.remma_epiAD import remma_epiAD_pair, remma_epiAD_eff, remma_epiAD_eff_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pheno_file = 'pheno'  # phenotypic file\n",
    "bed_file = 'plink'  # the prefix for the plink binary file\n",
    "\n",
    "# Step 1-3 is same to exact test\n",
    "\n",
    "# Step 4: Randomly select 100,000 SNP pairs\n",
    "snp_df = pd.read_csv(bed_file + '.bim', header=None, sep='\\s+')\n",
    "num_snp = snp_df.shape[0]  # the number of snp\n",
    "random_pairAD(num_snp, out_file='random_pairAD', num_pair=100000, num_each_pair=5000)\n",
    "\n",
    "# step 5: Test these 100,000 SNP pairs\n",
    "# note: set p_cut=1 to save all the results\n",
    "remma_epiAD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"random_pairAD\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAD_pair_random')\n",
    "\n",
    "# step 6: Calculate the median of variances for estimated epistatic SNP effects\n",
    "res_df = pd.read_csv('epiAD_pair_random', header=0, sep='\\s+')\n",
    "print(np.median(res_df['p']))  # P value close to 0.5. It means type I error controlled well\n",
    "var_median = np.median(res_df['var'])  # median of variances for estimated epistatic SNP effects\n",
    "\n",
    "# step 7: Screen the effects and select top SNP pairs based on approximate test. \n",
    "# Use the above median of variances as the approximate values (var_app = var_median)\n",
    "remma_epiAD_eff(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, var_app=var_median, \n",
    "                      p_cut=1e-05, out_file='epiAD_eff')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiAD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"epiAD_eff\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAD_pair_res')\n",
    "\n",
    "# Step 9: Select top SNPs and add the SNP position\n",
    "res_file = 'epiAD_pair_res'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Parallel approximate test (recommended for big data)\n",
    "Analysis can be subdivided with remma_epiAD_eff_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1-6 is same to the above\n",
    "\n",
    "# Step 7: parallel test. Write the codes in separate scripts and run separately.\n",
    "from gmat.remma.remma_epiAD import remma_epiAD_eff_parallel\n",
    "remma_epiAD_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,1], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='epiAD_eff_parallel')\n",
    "remma_epiAD_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,2], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='epiAD_eff_parallel')\n",
    "remma_epiAD_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,3], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='epiAD_eff_parallel')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiAD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"epiAD_eff_parallel.1\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAD_pair_res.1')\n",
    "remma_epiAD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"epiAD_eff_parallel.2\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAD_pair_res.2')\n",
    "remma_epiAD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"epiAD_eff_parallel.3\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiAD_pair_res.3')\n",
    "\n",
    "# Step 9: Merge files 'epiAD_pair_res.1', 'epiAD_pair_res.2' and 'epiAD_pair_res.3' \n",
    "# with the following codes.\n",
    "prefix = 'epiAD_pair_res'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1):\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 10: Select top SNPs and add the SNP position\n",
    "res_file = 'epiAD_pair_res.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Exhaustive dominance by dominance epistatis  \n",
    "Include additive, dominance, additive by additive, additive by dominance and dominance by dominance genomic relationship matrix  \n",
    "#### (1) Exact test (for small data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gmat.gmatrix import agmat, dgmat_as\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma.remma_epiDD import remma_epiDD, remma_epiDD_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pheno_file = 'pheno'\n",
    "bed_file = 'plink'\n",
    "\n",
    "# Step 1: Calculate the genomic relationship matrix\n",
    "agmat_lst = agmat(bed_file, inv=False) # additive genomic relationship matrix\n",
    "dgmat_lst = dgmat_as(bed_file, inv=False) # dominace genomic relationship matrix\n",
    "\n",
    "# Step 2: Prepare the phenotypic vector (y), designed matrix for fixed effects (xmat) and designed matrix for random effects (zmat)\n",
    "y, xmat, zmat = design_matrix_wemai_multi_gmat(pheno_file, bed_file)\n",
    "\n",
    "# Step 3: Estimate the variances\n",
    "# agmat_lst[0]*agmat_lst[0] is the additive by additive genomic relationship matrix\n",
    "# agmat_lst[0]*dgmat_lst[0] is the additive by dominance genomic relationship matrix\n",
    "# dgmat_lst[0]*dgmat_lst[0] is the dominance by dominance genomic relationship matrix\n",
    "gmat_lst = [agmat_lst[0], dgmat_lst[0], agmat_lst[0]*agmat_lst[0], agmat_lst[0]*dgmat_lst[0], dgmat_lst[0]*dgmat_lst[0]]  \n",
    "\n",
    "var_com_all = wemai_multi_gmat(y, xmat, zmat, gmat_lst)\n",
    "print(var_com_all)  \n",
    "\"\"\"\n",
    "a list： [0] addtive variance; [1] dominace variance [2] additive by additive variance; [3] additive by dominance variance; \n",
    "[4] dominance by dominance variance; [5] residual variance\n",
    "\"\"\"\n",
    "\n",
    "# Step 4: Test\n",
    "remma_epiDD(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, p_cut=0.0001, out_file='epiDD')\n",
    "\n",
    "# Step 5: Select top SNPs and add the SNP position\n",
    "res_file = 'remma_epiDD'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Parallel exact test (for small data)\n",
    "Analysis can be subdivided with remma_epiDD_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1-3 is same to the above\n",
    "\n",
    "# Step 4: parallel test. Write the codes in separate scripts and run separately.\n",
    "from gmat.remma.remma_epiDD import remma_epiDD_parallel\n",
    "remma_epiDD_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,1], \n",
    "                         p_cut=0.0001, out_file='epiDD_parallel')\n",
    "remma_epiDD_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,2], \n",
    "                         p_cut=0.0001, out_file='epiDD_parallel')\n",
    "remma_epiDD_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,3], \n",
    "                         p_cut=0.0001, out_file='epiDD_parallel')\n",
    "\n",
    "# Step 5: Merge files 'epiAD_parallel.1', 'epiAD_parallel.2' and 'epiAD_parallel.3' with the following codes.\n",
    "prefix = 'epiDD_parallel'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1):\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 6: Select top SNPs and add the SNP position\n",
    "res_file = 'epiDD_parallel.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) approximate test (recommended for big data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "from gmat.gmatrix import agmat, dgmat_as\n",
    "from gmat.uvlmm.design_matrix import design_matrix_wemai_multi_gmat\n",
    "from gmat.uvlmm.uvlmm_varcom import wemai_multi_gmat\n",
    "from gmat.remma import random_pair\n",
    "from gmat.remma.remma_epiDD import remma_epiDD_pair, remma_epiDD_eff, remma_epiDD_eff_parallel\n",
    "from gmat.remma import annotation_snp_pos\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "pheno_file = 'pheno'  # phenotypic file\n",
    "bed_file = 'plink'  # the prefix for the plink binary file\n",
    "\n",
    "# Step 1-3 is same to exact test\n",
    "\n",
    "# Step 4: Randomly select 100,000 SNP pairs\n",
    "snp_df = pd.read_csv(bed_file + '.bim', header=None, sep='\\s+')\n",
    "num_snp = snp_df.shape[0]  # the number of snp\n",
    "random_pair(num_snp, out_file='random_pair', num_pair=100000, num_each_pair=5000)\n",
    "\n",
    "# step 5: Test these 100,000 SNP pairs\n",
    "# note: set p_cut=1 to save all the results\n",
    "remma_epiDD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"random_pair\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiDD_pair_random')\n",
    "\n",
    "# step 6: Calculate the median of variances for estimated epistatic SNP effects\n",
    "res_df = pd.read_csv('epiDD_pair_random', header=0, sep='\\s+')\n",
    "print(np.median(res_df['p']))  # P value close to 0.5. It means type I error controlled well\n",
    "var_median = np.median(res_df['var'])  # median of variances for estimated epistatic SNP effects\n",
    "\n",
    "# step 7: Screen the effects and select top SNP pairs based on approximate test. \n",
    "# Use the above median of variances as the approximate values (var_app = var_median)\n",
    "remma_epiDD_eff(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, var_app=var_median, \n",
    "                      p_cut=1e-05, out_file='epiDD_eff')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiDD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"epiDD_eff\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiDD_pair_res')\n",
    "\n",
    "# Step 9: Select top SNPs and add the SNP position\n",
    "res_file = 'epiDD_pair_res'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) Parallel approximate test (recommended for big data)\n",
    "Analysis can be subdivided with remma_epiAD_eff_parallel and run parallelly on different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1-6 is same to the above\n",
    "\n",
    "# Step 7: parallel test. Write the codes in separate scripts and run separately.\n",
    "from gmat.remma.remma_epiDD import remma_epiDD_eff_parallel\n",
    "remma_epiDD_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,1], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='epiDD_eff_parallel')\n",
    "remma_epiDD_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,2], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='epiDD_eff_parallel')\n",
    "remma_epiDD_eff_parallel(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, parallel=[3,3], \n",
    "                               var_app=var_median, p_cut=1.0e-5, out_file='epiDD_eff_parallel')\n",
    "\n",
    "# Step 8: Calculate exact p values for top SNP pairs\n",
    "remma_epiDD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"epiDD_eff_parallel.1\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiDD_pair_res.1')\n",
    "remma_epiDD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"epiDD_eff_parallel.2\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiDD_pair_res.2')\n",
    "remma_epiDD_pair(y, xmat, zmat, gmat_lst, var_com=var_com_all, bed_file=bed_file, snp_pair_file=\"epiDD_eff_parallel.3\", \n",
    "                     max_test_pair=50000, p_cut=1, out_file='epiDD_pair_res.3')\n",
    "\n",
    "# Step 9: Merge files 'epiAD_pair_res.1', 'epiAD_pair_res.2' and 'epiAD_pair_res.3' \n",
    "# with the following codes.\n",
    "prefix = 'epiDD_pair_res'\n",
    "parallel_num = 3  # the number of parallels\n",
    "with open(prefix + \".merge\", 'w') as fout:\n",
    "    with open(prefix + '.1') as fin:\n",
    "        head_line = fin.readline()\n",
    "        fout.write(head_line)\n",
    "    for i in range(1, parallel_num+1):\n",
    "        with open(prefix + '.' + str(i)) as fin:\n",
    "            head_line = fin.readline()\n",
    "            for line in fin:\n",
    "                fout.write(line)\n",
    "\n",
    "# Step 10: Select top SNPs and add the SNP position\n",
    "res_file = 'epiDD_pair_res.merge'  # result file\n",
    "annotation_snp_pos(res_file, bed_file, p_cut=1.0e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
